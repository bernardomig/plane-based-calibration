\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[utf8]{inputenc}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{cleveref}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{  %Calibrations of Lidars on PTU devices\\
  %Calibration of Lidars on Kinematic chain(or Robotic Arm)\\
  %calibration marker free \dots blablabla
  %Plane based calibration for Lidars on Kinematic chain (or Robotic Arm)\\
  %blablbablab \dots for 3D reconstruction\\
  %Calibration of Lidar on Robotic Arm for 3D Reconstruction\\
  %Lidar Calibration for 3D Reconstruction\\
  %Calibration method for Lidars mounted on Robotic Arms\\
  %Using Planar based features for \dots\\
%A Lidar-hand calibration method using planar based features\\
  %Calibration of a Lidar based eye-in-hand system.\\
  %A planar based optmization for lidar based eye-in-hand calibration problem\\
  Lidar to end-effector calibration approach\\ using planar based features
  *\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
}

\maketitle

\begin{abstract}
\dots
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%% Notes %%%%

O que falar?
\begin{itemize}
    \item Para que pode servir esta calibração?
    \item Onde é usada? reconstrução de cenas, por exemplo; ou outros cenários onde a posição do laser é necessária de conhecer com elevada precisão.
    \item 
\end{itemize}

Problem formulation

What is a LRF (is 2D) -> produces 2D laser scans.



%%%%%%%%%%%%%%%%%%%%%%%%%%%

%TODO: Colocar reconstrucion para dar a motivação para o problema

% 
% Definition of the laser scanners and how the point clouds are generated.
%
Each laser scan is a set of range measurements taken along several directions but at the same time, all coincident with a plane, the scan plane. That is in fact why these equipments have  a 2D nature. Thus, for each scan, a 2D slice of the scene is measured.(The accumulation of these 2D slices produces the accumulated point cloud.) Since the LRF is mounted on top of an actuated kinematic chain (e.g. a PTU or robotic manipulator), the movement of this chain positions the LRF in different poses in the 3D space. Through the accumulation of the several laser scans, a dense point cloud of the scene is produced. 


% Explicação detalhada da acumulação e porque é impoortante a transformação do laser
The process of accumulation, in essence, is based on the concatenation of 3D points from multiple scans. However, the grouping of these points requires that the points of each laser scan are transformed to a common, static, reference frame, the map frame. In order to achieve this, one must apply a geometric transformation to each 3D point $\bold{p}^{(i)}$ measured in scan $i$, represented in the LRF's local coordinate system $l$. The transformed point $\bold{q}^{(i)}$, defined in the map reference frame, is determined by:
%
\begin{equation}
    \bold{q}^{(i)} = \, ^{m}\bold{T}_{e}^{(i)} \cdot ^{e}\bold{T}_{l} \cdot \bold{p}^{(i)},
\end{equation}
%
\noindent where ${^{m}\bold{T}_{e}}^{(i)}$ is the transformation between the map and the end effector coordinate frames, which is dynamic and given by the process that receives a description of the kinematic chain, the joint values at the scan $i$, and computes the direct kinematics. In turn, $^{e}\bold{T}_{l}$ denotes the position of the LRF w.r.t the end effector. 

Note that, although this transformation is static, it influences the coordinates of the points $\bold{q}^{(i)}$, and therefore is crucial to the accuracy with which three dimensional objects are represented in the accumulated point cloud.
Thus, an accurate estimation of transformation $^{e}\bold{T}_{l}$ is paramount to process of 3D reconstruction. We refer to this procedure of estimation the LRF to end effector transformation, as the Lidar to end-effector extrinsic calibration. 
To best of our knowledge, there is no straight forward, off-the-shelf methods for 
conducting this calibration, as will be detailed in \cref{sec:related_work}.

%TODO: Colocar aqui uma figura ilustrativa do problema

In this work, we propose a novel approach to perform Lidar to end-effector extrinsic calibration. The approach is based on an optimization procedure which computes the transformation that generates planar point cloud sections in areas which are marked as planes. To this end, several existing scene structures may be used, such as walls, ceilings or pavements. This is an additional advantage of our proposed method: it does not require dedicated calibration targets.

uses as objective function a measure of how similar to a plane portions of the point cloud are. These portions are segmente from the original point cloud using a manual one shot procedure. 

% By extrinsic calibration, we refer to the procedure which estimates the 6 DOF geometric transformation between the reference frame of the LRF and the reference frame of the end point of the kinematic, often referred to as the end-effector in robotic manipulators.
% This accumulation process is the core of all 3D reconstruction systems that use LRFs. However this reconstruction is highly affected the estimation of the position of the LRF to the mounting point in the kinematic chain. 
% IKn this case, there are no straight forwardof the shelf methods for conducting the extrinsic calibration of the LRF. By extrinsic calibration, we refer to the procedure which estimates the 6dof geometric transformation between the reference frame of the LRF and the reference frame of the end point of the kinematic, often refeered to as the end-effector in robotic manipulators. 
% a plane (What is a LS?) Each LS is registered to a static frame of reference, often called the base link, as in the following equation:



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}\label{sec:related_work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Ver aqui: https://ieeexplore.ieee.org/search/searchresult.jsp?queryText=laser%20range%20finder%20calibration&highlight=true&returnFacets=ALL&returnType=SEARCH&ranges=2010_2018_Year

Clustering of papers:

There are some papers which use planar structures. In 
In \cite{Kim2013}, a method for the extrinsic calibration is proposed that uses the normal verctor of two reference planes as metric for estimating the transformation. In blab

% Optimizações / Grid search / analytica





%In this paper, we present an algorithm for the extrinsic calibration method of rotating laser range finder (LRF). LRF is rotated about one axis using a motor therefore it is required to find the transformation between the motor and LRF to register scanned datum into one coordinate. We use calibration structure consisted of two planes to recover the transformation. Initial value of the transformation is set by hand and exhaustive search on the solution space is done. The fitness of the solution is evaluated using normal vector of the plane on the scene.


Pontos essenciais:
\begin{itemize}
    \item A calibração normalmente não é feita, por se conhecer a posição do laser por medições mecânicas;
    \item para protótipos e desenvolvimento, por vezes a posição do Lidar não é 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Approach}\label{sec:proposed_approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%The approach is based on an optimization procedure which computes the transformation that minimizes the distance between selected points of the accumulated point cloud and their corresponding planes.
A alternative method, the Planar Based Calibration, was developed in this work to calibrate the laser scanner in this system. One of the key differences to the previous method (in \cref{section:radlocc-method}) is that the calibration is done only using the laser range data, and the calibration from the PTU to the laser scanner is directly found (the transformation marked in blue in \cref{figure:geometric-transformation-graph}), so no camera is required. This method supposes that, in a good calibration, the deviation of a point set is minimal. In other words, in a point set representing a planar surface, the deviation from the points to the planar surface should be the lowest, if the extrinsic calibration is correct.

This method is, therefore, an optimization problem. For each extrinsic calibration transformation $\mathcal{T}$, corresponds a point cloud $\mathcal{P}$, following the method shown on \cref{section:point-registration}. This point cloud is evaluated by a cost function, which determines quantitatively how good each generated point cloud is. Finally, an optimizer will find the transformation $T$ that minimizes the loss function. Each one of these steps is described in detail next.

\subsubsection{Segmentation}

This calibration method uses an acquisition as its dataset, which is a significant advantage, since no calibrations patterns and no special apparatus is required, like chessboards or other markers. Also, a point cloud has to be generated using a estimation of the calibration transformation. This point cloud does not have to be geometrically accurate but the geometry should be perceivable for the plane segmentation, which is done manually prior to the calibration. In this work, the software CloudCompare was used to segment the point cloud into multiple planes, and the data was saved as a scalar index in each point. An example of a segmentation can be seen in \cref{figure:cluster-segmentation-1}, where each cluster is represented with a different color.

The segmentation was done manually because most segmentation algorithms, for example the RANSAC algorithm, were not capable of achieving a reliable segmentation for the initial estimate, because the point cloud had significant deformation. In addition, manual segmentation is easy to do and accurate, considering that it is a one-time process.

During the optimization, this segmentation serves as a blueprint for all the segmentations. Each point cloud is generated in the same way, so the sequence of points is always the same. Therefore, it is always possible to match any point on the generated point cloud to the point in the segmented point cloud, and get the corresponding cluster index for all the points.

\begin{figure}[h]
    \centering
    \includegraphics[width=.8\textwidth]{cluster-segmentation-1}
    \caption{Example of a plane segmentation, where each color represents a cluster.}
    \label{figure:cluster-segmentation-1}
\end{figure}

\subsubsection{Cost Function}
\label{section:calibration-cost-function}

The cost function is a measure used in optimization that compares the result of a model with its expected result, and returns a value that describes the dissimilarity between the two. More concretely, in this calibration the cost function has two steps: the cost is computed for each cluster and then the cost of all the clusters is combined into a single value, which is the final cost of the point cloud.

In an inicial step, the plane equation for each cluster is computed, using the Principal Component Analysis method, or PCA. First the centroid $\bar{p}$ of each plane is found, which is the same as the mean value of all the points $p: (x, y, z) \in \textbf{R}^3$:

\begin{equation}
    \bar{p} = \sum_{i}{p_i}.
        \label{eqn:centroid-plane}
\end{equation}

Then, the covariance matrix $\mathcal{C}$ is calculated:

\begin{equation}
    \mathcal{C} = \sum_{i}{(p_i - \bar{p}) \otimes (p_i - \bar{p})} \footnote{$\otimes$ is the outer tensor product.}.
        \label{eqn:covariance-matrix}
\end{equation}

Then, the principal axes of the plane is find by an eigen decomposition of the covariance matrix. The smallest eigenvalue $\lambda_3$ will be the variance $\sigma^2$ of the cluster. In other words, $\sigma^2$ is the mean square of the orthogonal distance of all points in the cluster to the plane. So, $\sigma^2$ can be a quantitative factor to measure the cost or each cluster. Formally, let us admit that the $\sigma^2$ has two components: the statistical error of the laser sensor $\sigma^2_{sensor}$, which is not affected by the calibration and a second component $\sigma^2_{calib}$, which depends of the calibration error. Thus, the idea is that, by minimizing $\sigma^2$, a exact calibration can be obtained. For this calibration, however, the value $\sigma$ was used instead of $\sigma^2$, which is known as the Root Mean Square Deviation, or RMS. Therefore, the loss of each cluster will be the $\sigma$ value.

Next, the scores of the clusters are combined into a scalar value, which is the error of the point cloud. The method found was to, again, calculate the RMS of the values of the partial losses $\textrm{loss}_i$, according to \cref{eqn:rms}. This value is expected to be minimal when all the partial losses are minimal which, according to this hypothesis, corresponds to a correct calibration.

\begin{equation}
    \label{eqn:rms}
    RMS = \sqrt{\sum_{i}^{N}{\textrm{loss}_i^2}}
\end{equation}

\subsubsection{Paramerization}

The parameters in this calibration are six values that define a geometric transformation in space, which is, in the end, a transformation matrix $T$ (\cref{eqn:transformation-matrix}). This transformation can be decomposed into two components, a translation and a rotation. The translation can be represented as the vector $t = (t_x, t_y, t_z)$, and the rotation can be represented as a $3 \times 3$ rotation matrix $R$. Since a rotation matrix has only $3 \times 3 = 9$ elements but only 3 degrees of freedom, another parameterization has to be used to represent a rotation. Popular parameterization for rotations are euler angles, quaternions and axis/angle representation. 

\begin{equation}
    \label{eqn:transformation-matrix}
    T = \left[
        \begin{array}{cccc}
            r_{11} & r_{12} & r_{13} & t_x \\
            r_{21} & r_{22} & r_{23} & t_y \\
            r_{31} & r_{32} & r_{33} & t_z \\
            0      & 0      & 0      & 1   
        \end{array}
    \right]
\end{equation}

However, not all representations are suitable for an optimization. In fact, in~\cite{hornegger99} the term fair parameterization was introduced: a parameterization is called fair, if it does not introduce more numerical sensitivity than the one inherent to the problem itself. Therefore, fair parameterization are a requirement for optimizations, as it increases the chances of convergence. For example, euler angles, which are probably the most used angle parameterization, are not suitable for optimizations~\cite{schmidt01}, because they do not yield smooth movements, each rotation is non-unique and, most notably, there are singularities, so-called \textit{gimbal-lock} singularities, where one degree of freedom is lost~\cite{schmidt01}. Also, quaternions are not suitable for optimizations, because quaternions have $4$ components which are constrained to an unitary length. Despite being a fair parameterization, quaternions introduce some complexity in the algorithm to handle this constrain, so they are not usually used for optimizations~\cite{schmidt01}.

The axis/angle parameterization is the most widely used to represent a rotation in an optimization, as it is a fair parameterization and has only three components. Any rotation can be represented as a rotation around an axis $a$, by an angle $\theta$. Since $a$ only represent the direction of the rotation (hence only has 2 degrees of freedom), it can be combined with the angle $\theta$ into a single vector $\omega = \left(\omega_1, \omega_2, \omega_3\right)$, as in \cref{eqn:axis-angle}.

\begin{equation}
    \label{eqn:axis-angle}
    \begin{aligned}
        \theta & = |\omega| \\
        a & = \frac{\omega}{|\omega|}
    \end{aligned}
\end{equation}

Computing the rotation matrix from $\omega$ is done using the Rodrigues' formula~(\cref{eqn:rogriguez-1,eqn:rogriguez-2})~\cite{schmidt01}:

\begin{align}
    \label{eqn:rogriguez-1}
    R = I + \frac{\sin \theta}{\theta} [\omega] + \frac{1 - \cos \theta}{\theta^2} [w] \\
    \label{eqn:rogriguez-2}
    [w] = \left[
        \begin{array}{ccc}
            0  & -\omega_3 & \omega_2 \\
            \omega_3 & 0   & -\omega_1 \\
            -\omega_2 & \omega_1 & 0 \\
        \end{array}
    \right],
\end{align}

\noindent
where I is the $3\times3$ identity matrix, $\theta$ is the angle and $\omega_1$, $\omega_2$ and $\omega_3$ are the components of $\omega$.

In conclusion, the parameter vector will have 6 values: 3 representing the translation ($t_1, t_2, t_3$) and 3 representing the rotation in the axis/angle representation ($r_1, r_2, r_3$). So, the parameter vector is shown in \cref{eqn:parameter-vector}.

\begin{equation}
    \label{eqn:parameter-vector}
    P = \{t_1, t_2, t_3, r_1, r_2, r_3\}
\end{equation}

\subsection{First Guess}

This optimization was quite robust to the initial parameters, so the first guess was always a null translation and the rotation was done doing a visual inspection of the laser scanner, using angles multiples of \SI{90}{\degree}.

\subsubsection{Optimizer}

The optimization is performed using the Powell's method, described in \cite{powell64}. This method finds a local minimum of a multi-dimensional unconstrained function, and does not require the gradient of this function (is unknown in this problem), which fits this particular optimization. This method is implemented in the python scientific library SciPy\footnote{See the Scipy reference in \url{https://docs.scipy.org/doc/scipy/reference/optimize.minimize-powell.html}.}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}\label{sec:results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work}\label{sec:conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




{\small
\bibliographystyle{IEEEtran}
\bibliography{references/refs}
}

%\begin{thebibliography}{00}
%\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
%\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
%\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
%\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
%\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
%\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
%\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
%\end{thebibliography}
\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
